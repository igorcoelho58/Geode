"""
GEODE SUPER CRAWLER V2.5 (Sistema de Fila Ãšnica)
=================================================
ARQUITETURA: Fila Ã© a ÃšNICA fonte de verdade
- Todas as ferramentas pendentes estÃ£o em fila_processamento.txt
- Script lÃª EXCLUSIVAMENTE da fila (nÃ£o usa lista hardcoded)
- Ferramentas sÃ£o DELETADAS da fila apÃ³s processamento com sucesso

FUNCIONALIDADES:
- Crawler Inteligente: Homepage + Pricing + Features + About + Extras
- Scraping Direto (SEM Google Search - Anti-Block)
- Busca MultilÃ­ngue YouTube (PT + EN + ES)
- Filtro de Qualidade: Descarta vÃ­deos < 3.000 caracteres
- Whisper AI PRIORIZADO: TranscriÃ§Ã£o local para vÃ­deos sem legendas
- Gemini 3.0 Flash Preview (1M tokens context)
- Sistema de DossiÃª: Salva dados brutos para auditoria
- ValidaÃ§Ã£o rigorosa: Cross-check de preÃ§os/recursos
- Output: Markdown puro para formataÃ§Ã£o manual

FORMATO DO ARQUIVO fila_processamento.txt:
Nome da Ferramenta | Categoria

Exemplo:
Notion | produtividade
Zapier | produtividade
HubSpot CRM | vendas

MENU:
1. Processar 5 ferramentas da fila (batch - ~15 min)
2. Processar 1 ferramenta da fila (primeira)
3. Processar ferramenta especÃ­fica da fila (buscar por nome)
4. Ver fila completa (ferramentas pendentes)
5. Sair

LIMITES (AI Studio - 28/12/2024):
- 20 requests/dia
- 5 requests/minuto
- 250K tokens/minuto
- Delay: 12s entre requests

FLUXO DE TRABALHO:
1. Edite fila_processamento.txt (adicione ferramentas no formato "Nome | Categoria")
2. Execute: python scripts/gerador_artigos_v2.py
3. Escolha opÃ§Ã£o (1, 2 ou 3)
4. Script processa e REMOVE automaticamente da fila
5. Repita atÃ© fila vazia (47 â†’ 0)

Autor: Igor Coelho / Refinado por Gemini
Data: 27/12/2024
Ãšltima AtualizaÃ§Ã£o: 29/12/2024 - V2.5 (Sistema de Fila Ãšnica)
"""

import os
import re
import time
import json
import requests
from datetime import datetime
from urllib.parse import quote_plus
from bs4 import BeautifulSoup

# Bibliotecas de IA e YouTube
import google.generativeai as genai
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter

# Whisper (IA local para transcriÃ§Ã£o) + yt-dlp (download de Ã¡udio)
try:
    import whisper  # type: ignore
    import yt_dlp  # type: ignore
    from tqdm import tqdm  # type: ignore
    WHISPER_DISPONIVEL = True
except ImportError:
    WHISPER_DISPONIVEL = False
    print("âš ï¸ Whisper nÃ£o instalado. Para fallback de IA local, instale: pip install openai-whisper yt-dlp tqdm")

# ============================================
# CONFIGURAÃ‡ÃƒO
# ============================================

API_KEY = "AIzaSyAGL5sgJDQauQJ5Es21vSdB4b3stP0D5A8"
BASE_PATH = r"c:\Users\Igor\Documents\Projetos\Geode\content"
DOSSIES_PATH = r"c:\Users\Igor\Documents\Projetos\Geode\data\dossies"
MODELO_GEMINI = "gemini-3-flash-preview"  # Modelo experimental mais avanÃ§ado (Gemini 3.0)

# ============================================
# LIMITES DA API GEMINI (Free Tier - Valores CONFIRMADOS via AI Studio)
# ============================================
# Fonte: https://aistudio.google.com/usage
# Limites verificados em 28/12/2024:
GEMINI_RPD = 20          # Requests Per Day (confirmado via AI Studio)
GEMINI_RPM = 5           # Requests Per Minute (confirmado via AI Studio)
GEMINI_TPM = 250000      # Tokens Per Minute (confirmado via AI Studio)
GEMINI_DELAY_MIN = 12    # Delay mÃ­nimo entre requests (segundos) = 60/RPM

# Contadores globais (serÃ£o resetados a cada execuÃ§Ã£o do script)
gemini_requests_hoje = 0
gemini_ultima_request = None
gemini_tokens_ultimo_minuto = []  # Lista de (timestamp, tokens) do Ãºltimo minuto

# Headers para fingir ser um navegador real
HEADERS_BROWSER = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7'
}

# PadrÃµes de URL para descoberta inteligente (ordem de prioridade)
VARIACOES_FEATURES = [
    "/features",
    "/product", 
    "/funcionalidades",
    "/recursos",
    "/tour",
    "/platform",
    "/capabilities",
    "/solutions",
    "/use-cases",
    "/customers",
    "/case-studies",
    "/why",
    "/how-it-works"
]

# Novas pÃ¡ginas para varredura extra (blog, reviews, etc)
VARIACOES_EXTRAS = [
    "/blog",
    "/resources",
    "/reviews",
    "/testimonials",
    "/demo",
    "/overview"
]

# Mapeamento de ferramentas
FERRAMENTAS_POR_CATEGORIA = {
    "atendimento": [
        "Intercom", "Octadesk", "Respond.io", "Take Blip", 
        "Tidio Chat", "Typebot", "Wati WhatsApp", "Zendesk Service"
    ],
    "marketing": [
        "ActiveCampaign", "Canva Pro", "Copy.ai", "Descript", "ElevenLabs",
        "Gamma App", "HeyGen AI", "InVideo AI", "Jasper AI", "Leadster",
        "Leonardo AI", "Midjourney", "mLabs", "Opus Clip", "Trakto Design"
    ],
    "produtividade": [
        "Asana", "Bitrix24", "ClickUp", "Conta Azul", "Fireflies AI",
        "Make.com", "Monday.com", "Notion", "Otter AI", "Pipefy",
        "Slack", "tldv.io", "Trello", "Zapier"
    ],
    "vendas": [
        "Apollo.io", "Clay AI", "Close CRM", "Freshsales CRM", "HubSpot CRM",
        "Kommo CRM", "Meetime", "Moskit CRM", "Pipedrive CRM", "Ploomes",
        "RD Station CRM", "Salesforce Starter", "Snov.io", "Zoho CRM"
    ]
}

PRIORIDADES = [
    "HubSpot CRM", "Pipedrive CRM", "RD Station CRM", 
    "ActiveCampaign", "Notion"  # TOP 5 (ajustado para seguranÃ§a de rate limit)
]

# Ferramentas secundÃ¡rias (processar depois)
SECUNDARIAS = [
    "ClickUp", "Zapier", "Monday.com", "Asana", "Trello"
]

# ============================================
# MAPEAMENTO DE URLS OFICIAIS
# ============================================

URLS_CONHECIDAS = {
    "hubspot crm": {"site": "https://www.hubspot.com/", "pricing": "https://www.hubspot.com/pricing/sales"},
    "pipedrive crm": {"site": "https://www.pipedrive.com/", "pricing": "https://www.pipedrive.com/pricing"},
    "rd station crm": {"site": "https://www.rdstation.com/", "pricing": "https://www.rdstation.com/pricing/"},
    "activecampaign": {"site": "https://www.activecampaign.com/", "pricing": "https://www.activecampaign.com/pricing"},
    "notion": {"site": "https://www.notion.so/", "pricing": "https://www.notion.so/pricing"},
    "clickup": {"site": "https://clickup.com/", "pricing": "https://clickup.com/pricing"},
    "zapier": {"site": "https://zapier.com/", "pricing": "https://zapier.com/pricing"},
    "monday.com": {"site": "https://monday.com/", "pricing": "https://monday.com/pricing"},
    "asana": {"site": "https://asana.com/", "pricing": "https://asana.com/pricing"},
    "trello": {"site": "https://trello.com/", "pricing": "https://trello.com/pricing"},
    "slack": {"site": "https://slack.com/", "pricing": "https://slack.com/pricing"},
    "agendor": {"site": "https://www.agendor.com.br/", "pricing": "https://www.agendor.com.br/planos/"},
    "chatwoot": {"site": "https://www.chatwoot.com/", "pricing": "https://www.chatwoot.com/pricing"},
    "manychat": {"site": "https://manychat.com/", "pricing": "https://manychat.com/pricing"}
}

# ============================================
# PROMPT OTIMIZADO V2 - SEM "SE ENTREGAR"
# ============================================

PROMPT_TEMPLATE = """VocÃª Ã© um analista sÃªnior de ferramentas SaaS para PMEs brasileiras. Sua especialidade Ã© criar anÃ¡lises profundas, honestas e humanizadas baseadas em pesquisa rigorosa de mercado.

**FERRAMENTA:** {nome_ferramenta}
**CATEGORIA:** {categoria}
**SITE OFICIAL:** {link_oficial}

---

## DADOS COLETADOS DA PESQUISA

### INFORMAÃ‡Ã•ES DO SITE OFICIAL (PreÃ§os, Features, Planos)
```
{texto_site}
```

### ANÃLISES DE MERCADO E REVIEWS DE USUÃRIOS
```
{transcricoes}
```

---

## INSTRUÃ‡Ã•ES DE ESCRITA

**TOM E ESTILO:**
- Escreva como um analista humano experiente que PESQUISOU a ferramenta
- NUNCA mencione "vÃ­deos", "transcriÃ§Ãµes", "anÃ¡lise de conteÃºdo" ou similares
- Use frases como: "Na prÃ¡tica observa-se que...", "UsuÃ¡rios relatam...", "A experiÃªncia mostra..."
- Seja crÃ­tico quando necessÃ¡rio - nÃ£o Ã© publieditorial

**INSTRUÃ‡ÃƒO CRÃTICA DE USO DAS FONTES:**
VocÃª DEVE integrar as informaÃ§Ãµes das duas seÃ§Ãµes acima (Site Oficial + AnÃ¡lises de Mercado) em sua anÃ¡lise. 
**NÃƒO IGNORE AS ANÃLISES DE MERCADO** - elas contÃªm experiÃªncias reais de usuÃ¡rios que sÃ£o essenciais para:
- Identificar problemas prÃ¡ticos que nÃ£o aparecem no site oficial
- Entender a curva de aprendizado real
- Avaliar a qualidade do suporte
- Citar casos de uso autÃªnticos
- Mencionar bugs ou limitaÃ§Ãµes conhecidas

**HIERARQUIA DE FONTES (MUITO IMPORTANTE):**
1. **SITE OFICIAL = VERDADE ABSOLUTA** - Use para preÃ§os, recursos, especificaÃ§Ãµes tÃ©cnicas
   - O criador da ferramenta NÃƒO colocaria informaÃ§Ã£o falsa no prÃ³prio site
   - Dados do site tÃªm credibilidade institucional e responsabilidade legal
   - Se o site diz "integra com Salesforce", vocÃª pode afirmar isso com certeza
   - **VALIDAÃ‡ÃƒO OBRIGATÃ“RIA**: SEMPRE cross-check preÃ§os e recursos do site oficial
   - Se uma anÃ¡lise mencionar "US$ 50/mÃªs" mas o site diz "US$ 75/mÃªs", use o valor do SITE

2. **ANÃLISES DE MERCADO E REVIEWS = EXPERIÃŠNCIA REAL** - Use para prÃ³s/contras, casos de uso, crÃ­ticas
   - OBRIGATÃ“RIO: Cite insights das anÃ¡lises em TODAS as seÃ§Ãµes do corpo (Como Funciona, Casos de Uso, etc)
   - OpiniÃµes de usuÃ¡rios podem ser subjetivas mas sÃ£o valiosas e DEVEM ser incluÃ­das
   - Use para humanizar a anÃ¡lise: "UsuÃ¡rios relatam que...", "Na prÃ¡tica, observa-se...", "Segundo especialistas..."
   - CrÃ­ticas negativas sÃ£o importantes - inclua quando relevantes nos CONTRAS
   - **ATENÃ‡ÃƒO**: Se anÃ¡lise contradizer o site oficial em FATOS (preÃ§os/recursos), priorize o SITE
   - Use anÃ¡lises para EXPERIÃŠNCIAS SUBJETIVAS (facilidade de uso, suporte, bugs, satisfaÃ§Ã£o), nÃ£o para specs

**CONTEÃšDO:**
- Use os dados do site oficial para PREÃ‡OS EXATOS, RECURSOS, INTEGRAÃ‡Ã•ES, PLANOS (verdade absoluta)
- **OBRIGATÃ“RIO**: Use as anÃ¡lises de mercado para EXPERIÃŠNCIA DE USO, PRÃ“S/CONTRAS REAIS, CASOS PRÃTICOS
- Traduza todo conteÃºdo internacional automaticamente para PT-BR natural
- PreÃ§os em Reais quando disponÃ­vel, caso contrÃ¡rio indique a moeda original
- **VALIDAÃ‡ÃƒO**: Cada seÃ§Ã£o do corpo DEVE conter pelo menos uma referÃªncia indireta Ã s anÃ¡lises de usuÃ¡rios

**FORMATAÃ‡ÃƒO:**
- Output em Markdown puro, SEM HTML
- Estrutura: Hook â†’ Description â†’ Veredito â†’ O que Ã© â†’ Para quem â†’ PrÃ³s â†’ Contras â†’ PreÃ§os â†’ Corpo â†’ FAQ

---

## OUTPUT ESPERADO (MARKDOWN PURO)

### HOOK (50-80 caracteres)
[Frase impactante sobre o principal benefÃ­cio]

### DESCRIPTION (150-250 caracteres)  
[DescriÃ§Ã£o completa para SEO]

### VEREDITO (80-120 palavras)
[AnÃ¡lise crÃ­tica: para quem Ã© ideal, quando vale, quando evitar]

### O QUE Ã‰? (80-120 palavras)
[ExplicaÃ§Ã£o objetiva: problema que resolve, pÃºblico-alvo]

### PARA QUEM Ã‰ INDICADO? (100-150 palavras)
[Perfil ideal de usuÃ¡rio, quando NÃƒO Ã© recomendado]

### PRÃ“S
- [Item 1 - sem emoji, 10-15 palavras]
- [Item 2]
- [Continue... mÃ­nimo 5, mÃ¡ximo 8]

### CONTRAS  
- [Item 1 - sem emoji, 10-15 palavras]
- [Item 2]
- [Continue... mÃ­nimo 4, mÃ¡ximo 7]

### PREÃ‡OS (use EXATAMENTE os dados do site oficial)
**PLANO 1:**
- Nome: [Ex: Gratuito]
- PreÃ§o: [Ex: R$ 0/mÃªs ou US$ 0/month]
- DescriÃ§Ã£o: [1 linha sobre o que inclui]

**PLANO 2:**
- Nome: [Ex: Starter]  
- PreÃ§o: [Ex: R$ 149/mÃªs ou US$ 20/user/month]
- DescriÃ§Ã£o: [1 linha]

[Continue com TODOS os planos listados no site]

### CORPO DA ANÃLISE

## Como Funciona na PrÃ¡tica?
[300-400 palavras: experiÃªncia de uso, onboarding, interface, curva de aprendizado]

## Casos de Uso Reais  
[250-350 palavras: 3-4 cenÃ¡rios prÃ¡ticos de PMEs brasileiras]

## Recursos Principais
[300-400 palavras: principais funcionalidades e diferenciais]

## IntegraÃ§Ãµes e Ecossistema
[150-200 palavras: integraÃ§Ãµes disponÃ­veis, API, marketplace]

## Nossa AvaliaÃ§Ã£o Final
[150-200 palavras: resumo crÃ­tico, custo-benefÃ­cio, recomendaÃ§Ã£o]

### FAQ (5-7 perguntas em formato YAML)
```yaml
faq:
  - question: "[Pergunta relevante sobre funcionalidade/preÃ§o/uso]"
    answer: "[Resposta direta, 80-150 palavras]"
  
  - question: "[Pergunta sobre integraÃ§Ã£o/limitaÃ§Ã£o]"
    answer: "[Resposta objetiva]"
  
  [Continue com mais 3-5 perguntas pertinentes]
```

### VALIDAÃ‡ÃƒO
- Data da AnÃ¡lise: {data_hoje}
- Link Oficial Validado: âœ… {link_oficial}
- PreÃ§os Confirmados: âœ… ExtraÃ­dos diretamente do site oficial
- PÃ¡ginas do Site Coletadas: {paginas_coletadas}
- VÃ­deos Analisados: {total_videos} vÃ­deos{urls_videos}
- TranscriÃ§Ãµes Lidas: {status_transcricoes}
- Idiomas das Fontes: {idiomas}
- Total de Caracteres Analisados: {total_caracteres}
- DossiÃª Completo Salvo: âœ… data/dossies/{slug_ferramenta}/

---

**LEMBRETE CRÃTICO:** VocÃª Ã© um ANALISTA HUMANO escrevendo uma PESQUISA. Nunca revele suas fontes tÃ©cnicas (vÃ­deos/transcriÃ§Ãµes). Escreva naturalmente.
"""

# ============================================
# FUNÃ‡Ã•ES AUXILIARES
# ============================================

def gerar_nome_arquivo(numero, titulo, extensao="txt", max_chars=50):
    """Gera nome de arquivo padronizado: 01_titulo_video.txt
    
    Args:
        numero: NÃºmero sequencial do arquivo (1, 2, 3...)
        titulo: TÃ­tulo original do vÃ­deo/conteÃºdo
        extensao: ExtensÃ£o do arquivo (txt, mp3, etc) sem o ponto
        max_chars: Limite mÃ¡ximo de caracteres para o tÃ­tulo
    
    Returns:
        String no formato: "01_titulo_truncado.txt"
    
    Exemplo:
        gerar_nome_arquivo(1, "Review Completo do Notion 2024", "txt")
        â†’ "01_Review_Completo_do_Notion_2024.txt"
    """
    # Remove caracteres proibidos em nomes de arquivo
    titulo_limpo = re.sub(r'[<>:"/\\|?*]', '', titulo)
    
    # Substitui espaÃ§os por underscores
    titulo_limpo = re.sub(r'\s+', '_', titulo_limpo.strip())
    
    # Limita tamanho e remove underscore final se houver
    titulo_limpo = titulo_limpo[:max_chars].rstrip('_')
    
    # Retorna formato: "01_titulo.ext"
    return f"{numero:02d}_{titulo_limpo}.{extensao}"

# ============================================
# FUNÃ‡Ã•ES DE WEB SCRAPING
# ============================================

def obter_urls_ferramenta(nome_ferramenta):
    """Retorna URLs do site oficial e variaÃ§Ãµes de pricing/features"""
    nome_lower = nome_ferramenta.lower()
    
    # Verifica se estÃ¡ no mapeamento manual (sempre prioritÃ¡rio)
    if nome_lower in URLS_CONHECIDAS:
        urls = URLS_CONHECIDAS[nome_lower]
        base_url = urls['site']
        return {
            "site": base_url,
            "pricing_urls": [urls['pricing']],
            "features_urls": [base_url.rstrip('/') + path for path in VARIACOES_FEATURES]
        }
    
    # Tenta inferir URLs baseado no nome
    slug = nome_lower.replace(" crm", "").replace(" ai", "").replace(" ", "")
    base_url = f"https://{slug}.com"
    
    # MÃºltiplas variaÃ§Ãµes de URL de pricing
    pricing_variations = [
        f"{base_url}/pricing",
        f"{base_url}/plans",
        f"{base_url}/planos",
        f"{base_url}/precos",
        f"{base_url}/price",
        f"{base_url}/buy"
    ]
    
    # MÃºltiplas variaÃ§Ãµes de URL de features
    features_variations = [base_url + path for path in VARIACOES_FEATURES]
    
    return {
        "site": base_url + "/",
        "pricing_urls": pricing_variations,
        "features_urls": features_variations
    }

def extrair_texto_limpo_site(url, limite_chars=None):
    """Entra na URL e extrai texto limpo (sem HTML). Retorna (texto, sucesso)
    
    limite_chars=None significa SEM LIMITE (vai com tudo!)
    """
    print(f"   ğŸŒ Acessando: {url}")
    
    try:
        response = requests.get(url, headers=HEADERS_BROWSER, timeout=30)
        if response.status_code != 200:
            print(f"   âŒ Status {response.status_code}")
            return None, False
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Remove elementos nÃ£o textuais
        for element in soup(['script', 'style', 'nav', 'footer', 'header', 'iframe', 'noscript']):
            element.decompose()
        
        # Extrai texto
        texto = soup.get_text(separator='\n', strip=True)
        
        # Limpa linhas vazias excessivas
        linhas = [line.strip() for line in texto.splitlines() if line.strip()]
        texto_limpo = '\n'.join(linhas)
        
        # Aplica limite SOMENTE se especificado
        tamanho_original = len(texto_limpo)
        if limite_chars and len(texto_limpo) > limite_chars:
            texto_limpo = texto_limpo[:limite_chars] + "\n[...conteÃºdo truncado...]"
            print(f"   âœ… ExtraÃ­dos {len(texto_limpo)} chars (truncado de {tamanho_original})")
        else:
            print(f"   âœ… ExtraÃ­dos {len(texto_limpo)} caracteres (COMPLETO)")
        return texto_limpo, True
        
    except requests.exceptions.RequestException as e:
        print(f"   âš ï¸ Erro: {e}")
        return None, False

def coletar_dados_site_oficial(nome_ferramenta):
    """Coleta dados completos: Homepage + Pricing + Features + About
    Retorna: (conteudo_completo_string, dados_estruturados_dict)
    """
    urls = obter_urls_ferramenta(nome_ferramenta)
    base_url = urls['site']
    
    print(f"\nğŸ“„ Coletando dados do site oficial...")
    
    conteudo_completo = ""
    dados_estruturados = {
        "homepage": {"url": base_url, "texto": None, "sucesso": False},
        "pricing": {"url": None, "texto": None, "sucesso": False},
        "features": {"url": None, "texto": None, "sucesso": False},
        "about": {"url": None, "texto": None, "sucesso": False}
    }
    
    # 1. HOMEPAGE (visÃ£o geral e posicionamento)
    print(f"\n   ğŸ  HOMEPAGE:")
    texto_home, sucesso_home = extrair_texto_limpo_site(base_url, limite_chars=None)
    if sucesso_home:
        dados_estruturados["homepage"]["texto"] = texto_home
        dados_estruturados["homepage"]["sucesso"] = True
        conteudo_completo += f"\n{'='*70}\n"
        conteudo_completo += f"HOMEPAGE - {base_url}\n"
        conteudo_completo += f"{'='*70}\n"
        conteudo_completo += texto_home + "\n"
    else:
        print(f"   âš ï¸ Homepage inacessÃ­vel")
    
    # 2. PRICING PAGE (preÃ§os exatos - ESSENCIAL)
    print(f"\n   ğŸ’° PRICING:")
    
    for pricing_url in urls['pricing_urls']:
        texto_pricing, sucesso_pricing = extrair_texto_limpo_site(pricing_url, limite_chars=None)
        if sucesso_pricing:
            dados_estruturados["pricing"]["url"] = pricing_url
            dados_estruturados["pricing"]["texto"] = texto_pricing
            dados_estruturados["pricing"]["sucesso"] = True
            conteudo_completo += f"\n{'='*70}\n"
            conteudo_completo += f"PRICING PAGE - {pricing_url}\n"
            conteudo_completo += f"{'='*70}\n"
            conteudo_completo += texto_pricing + "\n"
            break  # Achou pricing, para de tentar
    
    if not dados_estruturados["pricing"]["sucesso"]:
        print(f"   âš ï¸ Nenhuma pÃ¡gina de pricing encontrada (tentou {len(urls['pricing_urls'])} URLs)")
    
    # 3. FEATURES PAGE (funcionalidades tÃ©cnicas)
    print(f"\n   âš™ï¸ FEATURES:")
    
    for features_url in urls['features_urls']:
        texto_features, sucesso_features = extrair_texto_limpo_site(features_url, limite_chars=None)
        if sucesso_features:
            dados_estruturados["features"]["url"] = features_url
            dados_estruturados["features"]["texto"] = texto_features
            dados_estruturados["features"]["sucesso"] = True
            conteudo_completo += f"\n{'='*70}\n"
            conteudo_completo += f"FEATURES PAGE - {features_url}\n"
            conteudo_completo += f"{'='*70}\n"
            conteudo_completo += texto_features + "\n"
            break  # Achou features, para de tentar
    
    if not dados_estruturados["features"]["sucesso"]:
        print(f"   âš ï¸ Nenhuma pÃ¡gina de features encontrada (tentou {len(urls['features_urls'])} URLs)")
    
    # 4. ABOUT PAGE (informaÃ§Ãµes da empresa)
    print(f"\n   â„¹ï¸ ABOUT:")
    about_urls = [
        f"{base_url.rstrip('/')}/about",
        f"{base_url.rstrip('/')}/about-us",
        f"{base_url.rstrip('/')}/sobre",
        f"{base_url.rstrip('/')}/empresa"
    ]
    
    for about_url in about_urls:
        texto_about, sucesso_about = extrair_texto_limpo_site(about_url, limite_chars=None)
        if sucesso_about:
            dados_estruturados["about"]["url"] = about_url
            dados_estruturados["about"]["texto"] = texto_about
            dados_estruturados["about"]["sucesso"] = True
            conteudo_completo += f"\n{'='*70}\n"
            conteudo_completo += f"ABOUT PAGE - {about_url}\n"
            conteudo_completo += f"{'='*70}\n"
            conteudo_completo += texto_about + "\n"
            break  # Achou about, para de tentar
    
    # 5. PÃGINAS EXTRAS (blog, reviews, cases) - OPCIONAL MAS VALIOSO
    print(f"\n   ğŸ“š EXTRAS (blog, cases, reviews):")
    dados_estruturados["extras"] = []
    
    for path in VARIACOES_EXTRAS:
        extra_url = base_url.rstrip('/') + path
        texto_extra, sucesso_extra = extrair_texto_limpo_site(extra_url, limite_chars=100000)  # Limite maior para blogs
        
        if sucesso_extra:
            dados_estruturados["extras"].append({
                "tipo": path.replace('/', ''),
                "url": extra_url,
                "texto": texto_extra,
                "tamanho": len(texto_extra)
            })
            conteudo_completo += f"\n{'='*70}\n"
            conteudo_completo += f"EXTRA PAGE ({path}) - {extra_url}\n"
            conteudo_completo += f"{'='*70}\n"
            conteudo_completo += texto_extra + "\n"
            print(f"   âœ… {path}: {len(texto_extra)} chars")
            
            # Limita a 2 pÃ¡ginas extras para nÃ£o sobrecarregar
            if len(dados_estruturados["extras"]) >= 2:
                print(f"   â„¹ï¸ Limite de 2 pÃ¡ginas extras atingido")
                break
    
    if not dados_estruturados["extras"]:
        print(f"   â„¹ï¸ Nenhuma pÃ¡gina extra encontrada (nÃ£o Ã© crÃ­tico)")
    
    # Se nÃ£o conseguiu NADA, retorna mensagem
    if not conteudo_completo:
        return f"âš ï¸ NÃ£o foi possÃ­vel acessar nenhuma pÃ¡gina de {base_url}. Use conhecimento interno.", dados_estruturados
    
    print(f"\n   ğŸ“Š Coletados {len(conteudo_completo)} caracteres do site oficial")
    return conteudo_completo, dados_estruturados

# ============================================
# FUNÃ‡Ã•ES DE YOUTUBE MULTILÃNGUE
# ============================================

def transcrever_com_whisper(video_url, video_id, video_titulo, pasta_dossie=None, numero_video=None):
    """Baixa o Ã¡udio do YouTube e transcreve usando IA local (Whisper)
    FALLBACK quando youtube-transcript-api nÃ£o achar legendas oficiais
    
    Args:
        video_url: URL do vÃ­deo
        video_id: ID do vÃ­deo (usado como fallback no nome)
        video_titulo: TÃ­tulo do vÃ­deo para nome do arquivo
        pasta_dossie: Caminho do dossiÃª para salvar o Ã¡udio (opcional)
        numero_video: NÃºmero sequencial do vÃ­deo para nomenclatura (opcional)
    """
    if not WHISPER_DISPONIVEL:
        return None
    
    print(f"      ğŸ™ï¸ Transcrevendo via IA local (Whisper)...")
    
    # Define onde salvar o Ã¡udio
    if pasta_dossie and os.path.exists(pasta_dossie):
        # Cria subpasta de Ã¡udios no dossiÃª
        pasta_audios = os.path.join(pasta_dossie, "audios")
        os.makedirs(pasta_audios, exist_ok=True)
        
        # Usa nomenclatura padronizada com numeraÃ§Ã£o se disponÃ­vel
        if numero_video is not None:
            nome_arquivo = gerar_nome_arquivo(numero_video, video_titulo, "mp3")
            temp_audio = os.path.join(pasta_audios, nome_arquivo)
        else:
            # Fallback: usa tÃ­tulo limpo tradicional
            titulo_limpo = re.sub(r'[<>:"/\\|?*]', '', video_titulo)
            titulo_limpo = titulo_limpo[:100]
            temp_audio = os.path.join(pasta_audios, f"{titulo_limpo}.mp3")
    else:
        # Fallback: pasta temporÃ¡ria
        temp_audio = f"temp_audio_{video_id}.mp3"
    
    # ConfiguraÃ§Ãµes para baixar apenas o Ã¡udio (economia de banda)
    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '64',  # Baixa qualidade Ã© suficiente para voz
        }],
        'outtmpl': temp_audio.replace('.mp3', '.%(ext)s'),
        'quiet': True,
        'no_warnings': True,
        'match_filter': lambda info: None if (info.get('duration') or 0) > 300 else 'VÃ­deo muito curto (<5 min)',
    }

    try:
        # 1. Baixa o Ã¡udio do vÃ­deo
        print(f"         ğŸ“¥ Baixando Ã¡udio...")
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([video_url])
        
        # 2. Carrega o modelo Whisper (usa GPU NVIDIA se disponÃ­vel)
        # Modelos: tiny (rÃ¡pido, 75MB), base (bom, 150MB), small (melhor, 500MB)
        print(f"         ğŸ§  Carregando modelo de IA...")
        model = whisper.load_model("base")  # Compromise entre velocidade e qualidade
        
        # 3. Transcreve o arquivo (pode levar 1-3 minutos para vÃ­deos de 10 min)
        print(f"         â³ Processando transcriÃ§Ã£o (aguarde)...")
        
        # Barra de progresso durante transcriÃ§Ã£o
        with tqdm(total=100, desc="         Transcrevendo", ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:
            result = model.transcribe(temp_audio, fp16=False)  # AUTO-DETECT LANGUAGE!
            pbar.update(100)
        
        # Exibe idioma detectado
        idioma_detectado = result.get('language', 'desconhecido')
        texto_transcrito = result['text'].strip()
        print(f"         ğŸŒ Idioma detectado: {idioma_detectado}")
        print(f"         âœ… Whisper: {len(texto_transcrito):,} caracteres transcritos!")
        
        # 4. Valida tamanho mÃ­nimo (3000 chars) e DELETA Ã¡udio se muito curto
        TAMANHO_MINIMO = 3000
        if len(texto_transcrito) < TAMANHO_MINIMO:
            print(f"         âš ï¸ TranscriÃ§Ã£o muito curta ({len(texto_transcrito)} chars < {TAMANHO_MINIMO}). Descartando Ã¡udio...")
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
            return None  # Retorna None para indicar descarte
        
        # 5. Se chegou aqui, transcriÃ§Ã£o Ã© vÃ¡lida - mantÃ©m ou deleta conforme contexto
        if not pasta_dossie:
            # Se for temp (nÃ£o estÃ¡ no dossiÃª), aÃ­ sim deleta
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
        else:
            print(f"         ğŸ’¾ Ãudio salvo: {os.path.basename(temp_audio)}")
        
        return texto_transcrito

    except Exception as e:
        print(f"         âŒ Whisper falhou: {str(e)[:50]}")
        # Remove arquivo temporÃ¡rio em caso de erro (somente se nÃ£o estiver no dossiÃª)
        if not pasta_dossie and os.path.exists(temp_audio):
            os.remove(temp_audio)
        return None

def buscar_videos_multilingue(nome_ferramenta, limite_por_idioma=5, max_videos=25):
    """Busca vÃ­deos em PT, EN e ES com limite expandido para compensar descartes
    
    Args:
        limite_por_idioma: MÃ¡ximo de vÃ­deos por query
        max_videos: Limite total de vÃ­deos retornados (para evitar sobrecarga)
    """
    print(f"\nğŸ¥ Buscando reviews multilÃ­ngues (atÃ© {max_videos} vÃ­deos)...")
    
    videos_encontrados = []
    
    # Queries expandidas para garantir variedade
    queries = [
        (f"{nome_ferramenta} review vale a pena portuguÃªs", "PT-BR"),
        (f"{nome_ferramenta} tutorial completo brasil", "PT-BR"),
        (f"{nome_ferramenta} como usar tutorial", "PT-BR"),
        (f"{nome_ferramenta} review pros and cons", "EN"),
        (f"{nome_ferramenta} vs alternatives comparison", "EN"),
        (f"{nome_ferramenta} tutorial complete guide", "EN"),
        (f"{nome_ferramenta} opiniÃ³n espaÃ±ol", "ES"),
        (f"{nome_ferramenta} tutorial espaÃ±ol", "ES")
    ]
    
    for query, idioma in queries:
        # Para de buscar se jÃ¡ atingiu o limite
        if len(videos_encontrados) >= max_videos:
            break
            
        try:
            url = f"https://www.youtube.com/results?search_query={quote_plus(query)}"
            response = requests.get(url, headers=HEADERS_BROWSER, timeout=10)
            
            # Extrai IDs de vÃ­deos
            video_ids = re.findall(r'"videoId":"([^"]{11})"', response.text)
            titles = re.findall(r'"title":\{"runs":\[\{"text":"([^"]+)"\}\]', response.text)
            
            # Adiciona vÃ­deos Ãºnicos
            for i, vid in enumerate(video_ids[:limite_por_idioma]):
                if len(videos_encontrados) >= max_videos:
                    break
                if vid not in [v[0] for v in videos_encontrados] and i < len(titles):
                    videos_encontrados.append((vid, titles[i], idioma))
                    
        except Exception as e:
            print(f"   âš ï¸ Erro na busca {idioma}: {e}")
            continue
    
    print(f"   âœ… Encontrados {len(videos_encontrados)} vÃ­deos candidatos")
    return videos_encontrados

def extrair_transcricoes_multilingue(nome_ferramenta, pasta_dossie=None):
    """Extrai transcriÃ§Ãµes de forma AGRESSIVA (Whisper AI prioritÃ¡rio + fallback para legendas)
    COM FILTRO DE QUALIDADE: Descarta vÃ­deos muito curtos (< 3.000 chars)
    
    Args:
        nome_ferramenta: Nome da ferramenta
        pasta_dossie: Caminho do dossiÃª para salvar Ã¡udios (opcional)
        
    Retorna: (transcricoes_completas_string, idiomas_usados_list, videos_dados_list)
    """
    # Busca atÃ© 25 vÃ­deos para compensar possÃ­veis descartes (+ filtro >5min)
    videos = buscar_videos_multilingue(nome_ferramenta, max_videos=25)
    
    if not videos:
        return "Sem vÃ­deos encontrados no YouTube.", [], []
    
    print(f"\nğŸ“¥ Extraindo transcriÃ§Ãµes de {len(videos)} vÃ­deos (WHISPER PRIORITÃRIO + FILTRO QUALIDADE)...")
    
    # Cria instÃ¢ncia da API (necessÃ¡rio para usar .list())
    ytt_api = YouTubeTranscriptApi()
    
    transcricoes_completas = ""
    idiomas_usados = set()
    videos_dados = []
    videos_descartados = []
    count_sucesso = 0
    TAMANHO_MINIMO = 3000  # Caracteres mÃ­nimos para considerar vÃ­deo de qualidade
    
    for video_id, titulo, idioma_busca in videos:
        video_url = f"https://youtube.com/watch?v={video_id}"
        
        texto_final = None
        tipo_legenda = "desconhecida"
        idioma_final = idioma_busca
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PRIORIDADE 1: WHISPER AI (transcriÃ§Ã£o local sempre precisa)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if WHISPER_DISPONIVEL:
            print(f"   ğŸ™ï¸ Tentando Whisper IA primeiro...")
            texto_whisper = transcrever_com_whisper(video_url, video_id, titulo, pasta_dossie, count_sucesso + 1)
            
            if texto_whisper and len(texto_whisper) >= TAMANHO_MINIMO:
                texto_final = texto_whisper
                tipo_legenda = "whisper-ai"
                idioma_final = "pt (Whisper IA)"
                print(f"   âœ… Whisper: {len(texto_final):,} chars - {titulo[:50]}...")
            elif texto_whisper:
                # Whisper funcionou mas vÃ­deo muito curto
                videos_descartados.append({
                    "video_id": video_id,
                    "titulo": titulo,
                    "idioma": "pt (Whisper IA)",
                    "url": video_url,
                    "tamanho": len(texto_whisper),
                    "status": "descartado",
                    "motivo": f"VÃ­deo muito curto via Whisper ({len(texto_whisper)} chars < {TAMANHO_MINIMO} mÃ­nimo)"
                })
                print(f"   âš ï¸ Whisper DESCARTADO ({len(texto_whisper):,} chars < {TAMANHO_MINIMO:,} mÃ­nimo): {titulo[:50]}...")
                continue  # Pula para prÃ³ximo vÃ­deo
            else:
                # Whisper retornou None (vÃ­deo jÃ¡ foi descartado na funÃ§Ã£o)
                continue
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PRIORIDADE 2: LEGENDAS OFICIAIS (fallback se Whisper falhar)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if not texto_final:
            print(f"   ğŸ“œ Whisper falhou/indisponÃ­vel, tentando legendas oficiais...")
            
            try:
                # Tenta acessar lista de legendas (pode lanÃ§ar exceÃ§Ã£o)
                transcript_list = ytt_api.list(video_id)
                transcript = None
                
                # Tentativa 1: Legenda MANUAL nos idiomas preferidos
                try:
                    transcript = transcript_list.find_manually_created_transcript(['pt', 'pt-BR', 'en', 'en-US', 'es'])
                    tipo_legenda = "manual"
                except:
                    pass
                
                # Tentativa 2: Legenda AUTO-GERADA
                if not transcript:
                    try:
                        transcript = transcript_list.find_generated_transcript(['pt', 'pt-BR', 'en', 'en-US', 'es'])
                        tipo_legenda = "auto-gerada"
                    except:
                        pass
                
                # Tentativa 3: QUALQUER legenda disponÃ­vel
                if not transcript:
                    try:
                        for t in transcript_list:
                            transcript = t
                            tipo_legenda = "disponÃ­vel"
                            break
                    except:
                        pass
                
                # Se conseguiu alguma transcriÃ§Ã£o
                if transcript:
                    idioma_original = transcript.language_code
                    
                    # Traduz se necessÃ¡rio
                    if idioma_original not in ['pt', 'pt-BR', 'en', 'en-US', 'es']:
                        try:
                            transcript = transcript.translate('pt')
                            idioma_final = 'pt (traduzido)'
                        except:
                            idioma_final = idioma_original
                    else:
                        idioma_final = idioma_original
                    
                    # Baixa e formata
                    legendas_data = transcript.fetch()
                    formatter = TextFormatter()
                    texto_final = formatter.format_transcript(legendas_data)
                    
                    # Valida tamanho
                    if len(texto_final) < TAMANHO_MINIMO:
                        videos_descartados.append({
                            "video_id": video_id,
                            "titulo": titulo,
                            "idioma": idioma_final,
                            "url": video_url,
                            "tamanho": len(texto_final),
                            "status": "descartado",
                            "motivo": f"VÃ­deo muito curto ({len(texto_final)} chars < {TAMANHO_MINIMO} mÃ­nimo)"
                        })
                        print(f"   âš ï¸ Legendas DESCARTADAS ({len(texto_final):,} chars < {TAMANHO_MINIMO:,} mÃ­nimo): {titulo[:50]}...")
                        continue
                    
                    print(f"   âœ… Legenda {tipo_legenda} ({idioma_final}, {len(texto_final):,} chars): {titulo[:50]}...")
                    
            except Exception as e:
                # Nenhuma legenda disponÃ­vel
                videos_dados.append({
                    "video_id": video_id,
                    "titulo": titulo,
                    "idioma": idioma_busca,
                    "url": video_url,
                    "texto": None,
                    "tamanho": 0,
                    "status": "falha",
                    "erro": f"Sem legendas e Whisper falhou: {str(e)[:80]}"
                })
                print(f"   âŒ SEM LEGENDAS e Whisper falhou: {titulo[:50]}...")
                continue
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SALVA VÃDEO DE QUALIDADE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if texto_final:
            idiomas_usados.add(idioma_final)
            
            videos_dados.append({
                "video_id": video_id,
                "titulo": titulo,
                "idioma": idioma_final,
                "url": video_url,
                "texto": texto_final,
                "tamanho": len(texto_final),
                "status": "sucesso",
                "tipo_legenda": tipo_legenda
            })
            
            # Adiciona ao texto completo
            transcricoes_completas += f"\n{'='*60}\n"
            transcricoes_completas += f"REVIEW: {titulo}\n"
            transcricoes_completas += f"URL: {video_url}\n"
            transcricoes_completas += f"IDIOMA: {idioma_final} ({tipo_legenda})\n"
            transcricoes_completas += f"{'='*60}\n"
            transcricoes_completas += texto_final + "\n"
            
            count_sucesso += 1
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ’¾ SALVAR TRANSCRIÃ‡ÃƒO IMEDIATAMENTE (para validaÃ§Ã£o incremental)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if pasta_dossie:
                try:
                    # Cria pasta do dossiÃª se nÃ£o existir
                    os.makedirs(pasta_dossie, exist_ok=True)
                    
                    # Salva arquivo individual com nomenclatura padronizada
                    nome_arquivo = gerar_nome_arquivo(count_sucesso, titulo, "txt")
                    arquivo_saida = os.path.join(pasta_dossie, nome_arquivo)
                    with open(arquivo_saida, 'w', encoding='utf-8') as f:
                        f.write(f"VÃDEO #{count_sucesso}\n")
                        f.write(f"{'='*70}\n")
                        f.write(f"TÃ­tulo: {titulo}\n")
                        f.write(f"URL: {video_url}\n")
                        f.write(f"Idioma: {idioma_final} ({tipo_legenda})\n")
                        f.write(f"Tamanho: {len(texto_final)} caracteres\n")
                        f.write(f"Data Coleta: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
                        f.write(f"{'='*70}\n\n")
                        f.write(f" {texto_final}")
                    
                    print(f"   ğŸ’¾ Salvo: {nome_arquivo} ({len(texto_final):,} chars)")
                except Exception as e:
                    print(f"   âš ï¸ Erro ao salvar transcriÃ§Ã£o: {e}")
            
            # OTIMIZAÃ‡ÃƒO: Para de processar apÃ³s 5 vÃ­deos de qualidade
            if count_sucesso >= 5:
                print(f"   â„¹ï¸ Limite de 5 vÃ­deos de qualidade atingido")
                break
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VALIDAÃ‡ÃƒO FINAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if count_sucesso == 0:
        print(f"   âŒ NENHUMA transcriÃ§Ã£o de qualidade extraÃ­da de {len(videos)} vÃ­deos")
        print(f"   ğŸ’¡ POSSÃVEL BLOQUEIO DO YOUTUBE - Rate limit ou detecÃ§Ã£o de bot")
        print(f"   â¸ï¸ SOLUÃ‡ÃƒO: Aguarde 15-30 minutos e tente novamente")
        return "Nenhuma transcriÃ§Ã£o disponÃ­vel (vÃ­deos sem legendas ou muito curtos).", [], videos_dados + videos_descartados
    
    # VALIDAÃ‡ÃƒO CRÃTICA: MÃ­nimo de 5 vÃ­deos de qualidade (atualizado)
    if count_sucesso < 5:
        print(f"   âš ï¸ ATENÃ‡ÃƒO: Apenas {count_sucesso} vÃ­deo(s) de qualidade encontrado(s) (mÃ­nimo: 5)")
        if not WHISPER_DISPONIVEL:
            print(f"   ğŸ’¡ RecomendaÃ§Ã£o: Whisper nÃ£o estÃ¡ disponÃ­vel, poderia ajudar")
    
    # RelatÃ³rio final
    total_falhas = len([v for v in videos_dados if v.get('status') == 'falha'])
    print(f"   ğŸ“Š Total: {count_sucesso} vÃ­deos de qualidade âœ… + {len(videos_descartados)} descartados âš ï¸ + {total_falhas} falharam âŒ")
    
    if videos_descartados:
        print(f"   â„¹ï¸ VÃ­deos descartados por serem muito curtos: {len(videos_descartados)}")
    
    return transcricoes_completas, list(idiomas_usados), videos_dados + videos_descartados
    """Extrai transcriÃ§Ãµes de forma AGRESSIVA (manual + auto-gerada + traduzida)
    COM FILTRO DE QUALIDADE: Descarta vÃ­deos muito curtos (< 3.000 chars)
    Retorna: (transcricoes_completas_string, idiomas_usados_list, videos_dados_list)
    """
    # Busca atÃ© 25 vÃ­deos para compensar possÃ­veis descartes (+ filtro >5min)
    videos = buscar_videos_multilingue(nome_ferramenta, max_videos=25)
    
    if not videos:
        return "Sem vÃ­deos encontrados no YouTube.", [], []
    
    print(f"\nğŸ“¥ Extraindo transcriÃ§Ãµes de {len(videos)} vÃ­deos (MODO AGRESSIVO + FILTRO QUALIDADE)...")
    
    # Cria instÃ¢ncia da API (necessÃ¡rio para usar .list())
    ytt_api = YouTubeTranscriptApi()
    
    transcricoes_completas = ""
    idiomas_usados = set()
    videos_dados = []
    videos_descartados = []
    count_sucesso = 0
    TAMANHO_MINIMO = 3000  # Caracteres mÃ­nimos para considerar vÃ­deo de qualidade
    
    for video_id, titulo, idioma_busca in videos:
        video_url = f"https://youtube.com/watch?v={video_id}"
        
        transcript = None
        tipo_legenda = "desconhecida"
        
        # TENTATIVA 1: Buscar legendas oficiais (manual, auto-gerada ou qualquer uma)
        try:
            transcript_list = ytt_api.list(video_id)
            
            # Tentativa 1A: Legenda MANUAL nos idiomas preferidos
            try:
                transcript = transcript_list.find_manually_created_transcript(['pt', 'pt-BR', 'en', 'en-US', 'es'])
                tipo_legenda = "manual"
            except:
                pass
            
            # Tentativa 1B: Legenda AUTO-GERADA (aceita qualquer idioma)
            if not transcript:
                try:
                    transcript = transcript_list.find_generated_transcript(['pt', 'pt-BR', 'en', 'en-US', 'es'])
                    tipo_legenda = "auto-gerada"
                except:
                    pass
            
            # Tentativa 1C: QUALQUER legenda disponÃ­vel (Ãºltima tentativa)
            if not transcript:
                try:
                    # Pega a primeira que aparecer
                    for t in transcript_list:
                        transcript = t
                        tipo_legenda = "disponÃ­vel"
                        break
                except:
                    pass
        except Exception as e:
            # VÃ­deo nÃ£o tem legendas OU erro ao listar â†’ transcript continua None
            print(f"   âš ï¸ Sem legendas oficiais: {str(e)[:50]}...")
            pass
        
        # BRANCH 1: Se conseguiu legenda oficial do YouTube
        if transcript:
            try:
                # Tenta traduzir para PT se nÃ£o for PT/EN/ES
                idioma_original = transcript.language_code
                
                if idioma_original not in ['pt', 'pt-BR', 'en', 'en-US', 'es']:
                    try:
                        transcript = transcript.translate('pt')
                        idioma_final = 'pt (traduzido)'
                    except:
                        idioma_final = idioma_original
                else:
                    idioma_final = idioma_original
                
                # Baixa e formata
                legendas_data = transcript.fetch()
                formatter = TextFormatter()
                texto = formatter.format_transcript(legendas_data)
                
                idiomas_usados.add(idioma_final)
                
                # VALIDAÃ‡ÃƒO DE QUALIDADE: Descarta se muito curto
                if len(texto) < TAMANHO_MINIMO:
                    videos_descartados.append({
                        "video_id": video_id,
                        "titulo": titulo,
                        "idioma": idioma_final,
                        "url": video_url,
                        "tamanho": len(texto),
                        "status": "descartado",
                        "motivo": f"VÃ­deo muito curto ({len(texto)} chars < {TAMANHO_MINIMO} mÃ­nimo)"
                    })
                    print(f"   âš ï¸ DESCARTADO ({len(texto):,} chars < {TAMANHO_MINIMO:,} mÃ­nimo): {titulo[:50]}...")
                    continue  # Pula para prÃ³ximo vÃ­deo
                
                # Salva dados estruturados (apenas vÃ­deos de qualidade)
                videos_dados.append({
                    "video_id": video_id,
                    "titulo": titulo,
                    "idioma": idioma_final,
                    "url": video_url,
                    "texto": texto,
                    "tamanho": len(texto),
                    "status": "sucesso",
                    "tipo_legenda": tipo_legenda
                })
                
                # Adiciona ao texto completo
                transcricoes_completas += f"\n{'='*60}\n"
                transcricoes_completas += f"REVIEW: {titulo}\n"
                transcricoes_completas += f"URL: {video_url}\n"
                transcricoes_completas += f"IDIOMA: {idioma_final} (legenda {tipo_legenda})\n"
                transcricoes_completas += f"{'='*60}\n"
                transcricoes_completas += texto + "\n"
                
                count_sucesso += 1
                print(f"   âœ… Legenda {tipo_legenda} ({idioma_final}, {len(texto):,} chars): {titulo[:50]}...")
                
                # ğŸ’¾ SALVAR TRANSCRIÃ‡ÃƒO IMEDIATAMENTE (validaÃ§Ã£o incremental)
                if pasta_dossie:
                    try:
                        os.makedirs(pasta_dossie, exist_ok=True)
                        nome_arquivo = gerar_nome_arquivo(count_sucesso, titulo, "txt")
                        arquivo_saida = os.path.join(pasta_dossie, nome_arquivo)
                        with open(arquivo_saida, 'w', encoding='utf-8') as f:
                            f.write(f"VÃDEO #{count_sucesso}\n")
                            f.write(f"{'='*70}\n")
                            f.write(f"TÃ­tulo: {titulo}\n")
                            f.write(f"URL: {video_url}\n")
                            f.write(f"Idioma: {idioma_final} (legenda {tipo_legenda})\n")
                            f.write(f"Tamanho: {len(texto)} caracteres\n")
                            f.write(f"Data Coleta: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
                            f.write(f"{'='*70}\n\n")
                            f.write(f" {texto}")
                        print(f"   ğŸ’¾ Salvo: {nome_arquivo} ({len(texto):,} chars)")
                    except Exception as e:
                        print(f"   âš ï¸ Erro ao salvar: {e}")
                
                # OTIMIZAÃ‡ÃƒO: Para de processar apÃ³s 5 vÃ­deos de qualidade
                if count_sucesso >= 5:
                    print(f"   â„¹ï¸ Limite de 5 vÃ­deos de qualidade atingido")
                    break
            except Exception as e:
                print(f"   âš ï¸ Erro ao processar legenda oficial: {str(e)[:50]}...")
                # Mesmo com legenda encontrada, se houver erro no processamento, tenta Whisper
                transcript = None
        
        # BRANCH 2: Se NÃƒO conseguiu legenda oficial â†’ Tenta Whisper
        if not transcript:
            print(f"   âš ï¸ Sem legendas oficiais. Tentando Whisper (IA local)...")
            texto_whisper = transcrever_com_whisper(video_url, video_id)
            texto_whisper = transcrever_com_whisper(video_url, video_id)
            
            if texto_whisper:
                # VALIDAÃ‡ÃƒO DE QUALIDADE: Descarta se muito curto (mesmo via Whisper)
                if len(texto_whisper) < TAMANHO_MINIMO:
                    videos_descartados.append({
                        "video_id": video_id,
                        "titulo": titulo,
                        "idioma": 'pt (Whisper IA)',
                        "url": video_url,
                        "tamanho": len(texto_whisper),
                        "status": "descartado",
                        "motivo": f"VÃ­deo muito curto via Whisper ({len(texto_whisper)} chars < {TAMANHO_MINIMO} mÃ­nimo)"
                    })
                    print(f"   âš ï¸ Whisper DESCARTADO ({len(texto_whisper):,} chars < {TAMANHO_MINIMO:,} mÃ­nimo): {titulo[:50]}...")
                    continue
                
                idioma_final = 'pt (Whisper IA)'
                idiomas_usados.add(idioma_final)
                
                # Salva dados estruturados
                videos_dados.append({
                    "video_id": video_id,
                    "titulo": titulo,
                    "idioma": idioma_final,
                    "url": video_url,
                    "texto": texto_whisper,
                    "tamanho": len(texto_whisper),
                    "status": "sucesso",
                    "tipo_legenda": "whisper-ai"
                })
                
                # Adiciona ao texto completo
                transcricoes_completas += f"\n{'='*60}\n"
                transcricoes_completas += f"REVIEW: {titulo}\n"
                transcricoes_completas += f"URL: {video_url}\n"
                transcricoes_completas += f"IDIOMA: {idioma_final} (IA local)\n"
                transcricoes_completas += f"{'='*60}\n"
                transcricoes_completas += texto_whisper + "\n"
                
                count_sucesso += 1
                print(f"   âœ… Whisper AI ({len(texto_whisper):,} chars): {titulo[:50]}...")
                
                # ğŸ’¾ SALVAR TRANSCRIÃ‡ÃƒO IMEDIATAMENTE (validaÃ§Ã£o incremental)
                if pasta_dossie:
                    try:
                        os.makedirs(pasta_dossie, exist_ok=True)
                        nome_arquivo = gerar_nome_arquivo(count_sucesso, titulo, "txt")
                        arquivo_saida = os.path.join(pasta_dossie, nome_arquivo)
                        with open(arquivo_saida, 'w', encoding='utf-8') as f:
                            f.write(f"VÃDEO #{count_sucesso}\n")
                            f.write(f"{'='*70}\n")
                            f.write(f"TÃ­tulo: {titulo}\n")
                            f.write(f"URL: {video_url}\n")
                            f.write(f"Idioma: {idioma_final} (IA local)\n")
                            f.write(f"Tamanho: {len(texto_whisper)} caracteres\n")
                            f.write(f"Data Coleta: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
                            f.write(f"{'='*70}\n\n")
                            f.write(f" {texto_whisper}")
                        print(f"   ğŸ’¾ Salvo: {nome_arquivo} ({len(texto_whisper):,} chars)")
                    except Exception as e:
                        print(f"   âš ï¸ Erro ao salvar: {e}")
                
                # OTIMIZAÃ‡ÃƒO: Para de processar apÃ³s 5 vÃ­deos de qualidade
                if count_sucesso >= 5:
                    print(f"   â„¹ï¸ Limite de 5 vÃ­deos de qualidade atingido")
                    break
            else:
                # Whisper tambÃ©m falhou - marca como falha SOMENTE se Whisper estÃ¡ disponÃ­vel
                if WHISPER_DISPONIVEL:
                    videos_dados.append({
                        "video_id": video_id,
                        "titulo": titulo,
                        "idioma": idioma_busca,
                        "url": video_url,
                        "texto": None,
                        "tamanho": 0,
                        "status": "falha",
                        "erro": "Sem legendas oficiais e Whisper falhou"
                    })
                    print(f"   âŒ Whisper falhou: {titulo[:50]}...")
                else:
                    # Whisper nÃ£o disponÃ­vel - pula sem salvar (permite reprocessamento futuro)
                    print(f"   â­ï¸ Pulando (Whisper nÃ£o instalado): {titulo[:50]}...")
                continue
        
        # Se chegou aqui sem processar nada, algo deu errado (nÃ£o deveria acontecer)
        # continue para prÃ³ximo vÃ­deo
    
    if count_sucesso == 0:
        print(f"   âŒ NENHUMA transcriÃ§Ã£o de qualidade extraÃ­da de {len(videos)} vÃ­deos")
        print(f"   ğŸ’¡ POSSÃVEL BLOQUEIO DO YOUTUBE - Rate limit ou detecÃ§Ã£o de bot")
        print(f"   â¸ï¸ SOLUÃ‡ÃƒO: Aguarde 15-30 minutos e tente novamente")
        return "Nenhuma transcriÃ§Ã£o disponÃ­vel (vÃ­deos sem legendas ou muito curtos).", [], videos_dados + videos_descartados
    
    # VALIDAÃ‡ÃƒO CRÃTICA: MÃ­nimo de 3 vÃ­deos de qualidade para garantir anÃ¡lise confiÃ¡vel
    if count_sucesso < 3:
        print(f"   âš ï¸ ATENÃ‡ÃƒO: Apenas {count_sucesso} vÃ­deo(s) de qualidade encontrado(s)")
        print(f"   ğŸ’¡ RecomendaÃ§Ã£o: Instale Whisper para fallback (pip install openai-whisper yt-dlp)")
    
    # RelatÃ³rio final
    total_falhas = len([v for v in videos_dados if v.get('status') == 'falha'])
    print(f"   ğŸ“Š Total: {count_sucesso} vÃ­deos de qualidade âœ… + {len(videos_descartados)} descartados âš ï¸ + {total_falhas} sem legenda âŒ")
    
    if videos_descartados:
        print(f"   â„¹ï¸ VÃ­deos descartados por serem muito curtos: {len(videos_descartados)}")
    
    return transcricoes_completas, list(idiomas_usados), videos_dados + videos_descartados

# ============================================
# SISTEMA DE DOSSIÃŠ (AUDITORIA)
# ============================================

def salvar_dossie(nome_ferramenta, categoria, dados_site, videos_dados, idiomas):
    """Salva dados brutos coletados para auditoria e reutilizaÃ§Ã£o futura
    
    Estrutura criada:
    data/dossies/[ferramenta]/
      â”œâ”€â”€ metadata.json (resumo: data, URLs, idiomas, stats)
      â”œâ”€â”€ site_homepage.txt
      â”œâ”€â”€ site_pricing.txt
      â”œâ”€â”€ site_features.txt
      â”œâ”€â”€ site_about.txt
      â””â”€â”€ youtube_transcripts.txt (todas concatenadas)
    """
    nome_slug = nome_ferramenta.lower()
    nome_slug = re.sub(r'[^a-z0-9-]', '', nome_slug.replace(' ', '-'))
    
    pasta_dossie = os.path.join(DOSSIES_PATH, nome_slug)
    os.makedirs(pasta_dossie, exist_ok=True)
    
    print(f"\nğŸ“‚ Salvando dossiÃª em: {pasta_dossie}")
    
    # 1. Salvar pÃ¡ginas do site (arquivos separados)
    for tipo in ['homepage', 'pricing', 'features', 'about']:
        if dados_site[tipo]['sucesso'] and dados_site[tipo]['texto']:
            caminho = os.path.join(pasta_dossie, f"site_{tipo}.txt")
            with open(caminho, 'w', encoding='utf-8') as f:
                f.write(f"URL: {dados_site[tipo]['url']}\n")
                f.write(f"Data Coleta: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
                f.write(f"Tamanho: {len(dados_site[tipo]['texto'])} caracteres\n")
                f.write(f"{'='*70}\n\n")
                f.write(dados_site[tipo]['texto'])
            print(f"   ğŸ’¾ {tipo}: {len(dados_site[tipo]['texto'])} chars")
    
    # 2. Salvar transcriÃ§Ãµes do YouTube (CADA VÃDEO EM ARQUIVO SEPARADO + Ã­ndice)
    videos_com_sucesso = [v for v in videos_dados if v.get('status') == 'sucesso']
    videos_sem_legenda = [v for v in videos_dados if v.get('status') == 'falha']
    
    if videos_dados:
        # 2.1. Ãndice geral de vÃ­deos
        caminho_indice = os.path.join(pasta_dossie, "youtube_videos_indice.txt")
        with open(caminho_indice, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ“¹ ÃNDICE DE VÃDEOS ANALISADOS\n")
            f.write(f"{'='*70}\n")
            f.write(f"Data Coleta: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
            f.write(f"Total de VÃ­deos Encontrados: {len(videos_dados)}\n")
            f.write(f"VÃ­deos COM TranscriÃ§Ã£o: {len(videos_com_sucesso)}\n")
            f.write(f"VÃ­deos SEM TranscriÃ§Ã£o: {len(videos_sem_legenda)}\n")
            f.write(f"{'='*70}\n\n")
            
            for i, video in enumerate(videos_dados, 1):
                status_emoji = "âœ…" if video['status'] == 'sucesso' else "âŒ"
                f.write(f"{i}. {status_emoji} [{video['idioma']}] {video['titulo']}\n")
                f.write(f"   URL: {video['url']}\n")
                f.write(f"   Status: {video['status']}\n")
                if video['status'] == 'sucesso':
                    f.write(f"   Tamanho: {video['tamanho']} caracteres\n")
                    # Gera nome padronizado para referÃªncia
                    nome_arquivo_ref = gerar_nome_arquivo(i, video['titulo'], "txt")
                    f.write(f"   Arquivo: {nome_arquivo_ref}\n")
                else:
                    f.write(f"   Erro: {video.get('erro', 'Sem legendas disponÃ­veis')}\n")
                f.write(f"\n")
        
        print(f"   ğŸ’¾ YouTube Ãndice: {len(videos_dados)} vÃ­deos catalogados")
        
        # 2.2. Arquivos jÃ¡ foram salvos incrementalmente durante o processamento
        # (NÃ£o precisa reescrever aqui - jÃ¡ salvamos com gerar_nome_arquivo)
        
        if videos_com_sucesso:
            total_chars_yt = sum(v['tamanho'] for v in videos_com_sucesso)
            print(f"   ğŸ’¾ YouTube TranscriÃ§Ãµes: {len(videos_com_sucesso)} arquivos, {total_chars_yt:,} chars total")
    
    # 3. Salvar metadata (JSON para fÃ¡cil parsing futuro)
    metadata = {
        "ferramenta": nome_ferramenta,
        "categoria": categoria,
        "data_coleta": datetime.now().strftime('%d/%m/%Y %H:%M'),
        "site": {
            "homepage": {
                "url": dados_site['homepage']['url'],
                "coletado": dados_site['homepage']['sucesso'],
                "tamanho": len(dados_site['homepage']['texto']) if dados_site['homepage']['texto'] else 0
            },
            "pricing": {
                "url": dados_site['pricing']['url'],
                "coletado": dados_site['pricing']['sucesso'],
                "tamanho": len(dados_site['pricing']['texto']) if dados_site['pricing']['texto'] else 0
            },
            "features": {
                "url": dados_site['features']['url'],
                "coletado": dados_site['features']['sucesso'],
                "tamanho": len(dados_site['features']['texto']) if dados_site['features']['texto'] else 0
            },
            "about": {
                "url": dados_site['about']['url'],
                "coletado": dados_site['about']['sucesso'],
                "tamanho": len(dados_site['about']['texto']) if dados_site['about']['texto'] else 0
            }
        },
        "youtube": {
            "total_videos_encontrados": len(videos_dados),
            "videos_com_transcricao": len([v for v in videos_dados if v.get('status') == 'sucesso']),
            "videos_sem_transcricao": len([v for v in videos_dados if v.get('status') == 'falha']),
            "idiomas": idiomas,
            "videos": [
                {
                    "titulo": v['titulo'],
                    "url": v['url'],
                    "idioma": v['idioma'],
                    "status": v.get('status', 'desconhecido'),
                    "tamanho": v.get('tamanho', 0),
                    "erro": v.get('erro', None) if v.get('status') == 'falha' else None
                }
                for v in videos_dados
            ]
        },
        "estatisticas": {
            "total_chars_site": sum(
                len(dados_site[t]['texto']) if dados_site[t]['texto'] else 0 
                for t in ['homepage', 'pricing', 'features', 'about']
            ),
            "total_chars_youtube": sum(v.get('tamanho', 0) for v in videos_dados if v.get('status') == 'sucesso'),
            "paginas_coletadas": sum(1 for t in ['homepage', 'pricing', 'features', 'about'] if dados_site[t]['sucesso']),
            "videos_encontrados": len(videos_dados),
            "videos_com_transcricao": len([v for v in videos_dados if v.get('status') == 'sucesso']),
            "videos_sem_transcricao": len([v for v in videos_dados if v.get('status') == 'falha'])
        }
    }
    
    caminho_metadata = os.path.join(pasta_dossie, "metadata.json")
    with open(caminho_metadata, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    videos_msg = f"{len(videos_dados)} vÃ­deos ({len([v for v in videos_dados if v.get('status') == 'sucesso'])} com transcriÃ§Ã£o)"
    print(f"   ğŸ’¾ Metadata: {metadata['estatisticas']['paginas_coletadas']} pÃ¡ginas + {videos_msg}")
    print(f"   âœ… DossiÃª completo salvo!\n")

# ============================================
# CONTROLE DE RATE LIMITING GEMINI
# ============================================

def estimar_tokens(texto):
    """Estimativa grosseira: 1 token â‰ˆ 4 caracteres para PT-BR"""
    return len(texto) // 4

def aguardar_rate_limit():
    """Aguarda o tempo necessÃ¡rio para respeitar RPM (5 requests/min)
    
    Retorna: True se pode prosseguir, False se atingiu limite diÃ¡rio
    """
    global gemini_requests_hoje, gemini_ultima_request, gemini_tokens_ultimo_minuto
    
    # Verifica limite diÃ¡rio
    if gemini_requests_hoje >= GEMINI_RPD:
        print(f"\nâŒ LIMITE DIÃRIO ATINGIDO ({GEMINI_RPD} requests)")
        print(f"   â¸ï¸ Processamento pausado. Continue amanhÃ£!")
        return False
    
    agora = time.time()
    
    # Remove tokens de mais de 1 minuto atrÃ¡s
    gemini_tokens_ultimo_minuto = [
        (ts, tokens) for ts, tokens in gemini_tokens_ultimo_minuto 
        if agora - ts < 60
    ]
    
    # Calcula delay necessÃ¡rio
    if gemini_ultima_request:
        tempo_desde_ultima = agora - gemini_ultima_request
        if tempo_desde_ultima < GEMINI_DELAY_MIN:
            delay = GEMINI_DELAY_MIN - tempo_desde_ultima
            print(f"   â¸ï¸ Rate limiting: aguardando {delay:.1f}s...")
            time.sleep(delay)
    
    return True

def registrar_request_gemini(tokens_estimados):
    """Registra uma request ao Gemini para controle de limites"""
    global gemini_requests_hoje, gemini_ultima_request, gemini_tokens_ultimo_minuto
    
    gemini_requests_hoje += 1
    gemini_ultima_request = time.time()
    gemini_tokens_ultimo_minuto.append((time.time(), tokens_estimados))
    
    # Calcula TPM atual
    tokens_ultimo_min = sum(t for _, t in gemini_tokens_ultimo_minuto)
    
    print(f"   ğŸ“Š Gemini: Request {gemini_requests_hoje}/{GEMINI_RPD} | Tokens/min: {tokens_ultimo_min:,}/{GEMINI_TPM:,}")

# ============================================
# PROCESSAMENTO PRINCIPAL
# ============================================

def processar_ferramenta(nome_ferramenta, categoria, model):
    """Processa uma ferramenta: Site + YouTube + Gemini"""
    
    print(f"\n{'='*70}")
    print(f"ğŸš€ PROCESSANDO: {nome_ferramenta} ({categoria})")
    print(f"{'='*70}")
    
    # 0. VERIFICAÃ‡ÃƒO: Pula se jÃ¡ foi processado
    nome_arquivo = nome_ferramenta.lower()
    nome_arquivo = re.sub(r'[^a-z0-9-]', '', nome_arquivo.replace(' ', '-'))
    pasta_categoria = os.path.join(BASE_PATH, categoria)
    caminho = os.path.join(pasta_categoria, f"{nome_arquivo}_raw.md")
    
    if os.path.exists(caminho):
        print(f"   â­ï¸ JÃ PROCESSADO anteriormente - pulando...")
        print(f"   ğŸ“„ Arquivo existente: {caminho}")
        return caminho
    
    # 0.1. Prepara pasta do dossiÃª ANTES de coletar (para Whisper salvar Ã¡udios)
    pasta_dossie = os.path.join(DOSSIES_PATH, nome_arquivo)
    os.makedirs(pasta_dossie, exist_ok=True)
    
    # 1. COLETA: Site Oficial
    urls = obter_urls_ferramenta(nome_ferramenta)
    link_oficial = urls['site']
    texto_site, dados_site = coletar_dados_site_oficial(nome_ferramenta)
    
    # 2. COLETA: Reviews MultilÃ­ngues (PASSA pasta_dossie para Whisper)
    transcricoes, idiomas, videos_dados = extrair_transcricoes_multilingue(nome_ferramenta, pasta_dossie)
    
    # 2.1. VALIDAÃ‡ÃƒO CRÃTICA: Se menos de 5 vÃ­deos foram extraÃ­dos, PULA ferramenta
    videos_com_sucesso = [v for v in videos_dados if v.get('status') == 'sucesso']
    
    if len(videos_com_sucesso) < 5:
        print(f"\n   âš ï¸ FALHA CRÃTICA: Apenas {len(videos_com_sucesso)} vÃ­deo(s) extraÃ­do(s) (mÃ­nimo: 5)")
        print(f"   ğŸ’¡ PossÃ­vel bloqueio do YouTube (rate limit/detecÃ§Ã£o de bot)")
        print(f"   â­ï¸ PULANDO {nome_ferramenta} - reprocessar depois")
        print(f"   â„¹ï¸ NÃƒO salvando dossiÃª nem _raw.md (permite reprocessamento)\n")
        return None
    
    # 3. SALVAR DOSSIÃŠ (Auditoria e ReutilizaÃ§Ã£o)
    salvar_dossie(nome_ferramenta, categoria, dados_site, videos_dados, idiomas)
    
    # 4. CONTROLE DE RATE LIMITING (ANTES de chamar Gemini)
    if not aguardar_rate_limit():
        print(f"   âš ï¸ {nome_ferramenta} coletado mas NÃƒO analisado (limite diÃ¡rio)")
        print(f"   ğŸ’¾ DossiÃª salvo - reprocessar amanhÃ£ com Gemini")
        return None
    
    # 5. GEMINI: Gera anÃ¡lise
    total_chars = len(texto_site) + len(transcricoes)
    tokens_estimados = estimar_tokens(texto_site + transcricoes + PROMPT_TEMPLATE)
    
    print(f"\nğŸ¤– Gemini processando {total_chars:,} caracteres (~{tokens_estimados:,} tokens)...")
    print(f"   ğŸ“Š Site: {len(texto_site):,} chars | YouTube: {len(transcricoes):,} chars ({len(videos_com_sucesso)} vÃ­deos)")
    
    # Calcula estatÃ­sticas para validaÃ§Ã£o
    paginas_site = sum(1 for t in ['homepage', 'pricing', 'features', 'about'] if dados_site[t]['sucesso'])
    if 'extras' in dados_site and dados_site['extras']:
        paginas_site += len(dados_site['extras'])
    
    urls_videos_str = ""
    if videos_dados:
        urls_list = [f"\n  - {v['url']} ({v['idioma']})" for v in videos_dados[:5]]  # Primeiros 5
        urls_videos_str = "".join(urls_list)
    
    status_transcricoes = "âœ… Analisadas e integradas" if videos_dados else "âš ï¸ Nenhuma transcriÃ§Ã£o disponÃ­vel"
    
    prompt = PROMPT_TEMPLATE.format(
        nome_ferramenta=nome_ferramenta,
        categoria=categoria,
        link_oficial=link_oficial,
        texto_site=texto_site,
        transcricoes=transcricoes,
        data_hoje=datetime.now().strftime('%d/%m/%Y'),
        idiomas=", ".join(idiomas) if idiomas else "PT-BR (conhecimento interno)",
        paginas_coletadas=f"{paginas_site} pÃ¡ginas",
        total_videos=len(videos_dados),
        urls_videos=urls_videos_str,
        status_transcricoes=status_transcricoes,
        total_caracteres=f"{total_chars:,} caracteres",
        slug_ferramenta=nome_arquivo
    )
    
    try:
        # Registra request ANTES de chamar (para controle preciso)
        registrar_request_gemini(tokens_estimados)
        
        response = model.generate_content(prompt)
        conteudo = response.text
        print(f"   âœ… AnÃ¡lise gerada! ({len(conteudo)} caracteres)")
        
    except Exception as e:
        print(f"   âŒ Erro no Gemini: {e}")
        # Decrementa contador se falhou (nÃ£o contabiliza como request bem-sucedida)
        global gemini_requests_hoje
        gemini_requests_hoje -= 1
        return None
    
    # 5. SALVAR ANÃLISE FINAL (Markdown puro - formataÃ§Ã£o manual depois)
    # Nome do arquivo jÃ¡ calculado no inÃ­cio da funÃ§Ã£o
    conteudo_final = f"""---
ANÃLISE GERADA AUTOMATICAMENTE - REQUER FORMATAÃ‡ÃƒO
Ferramenta: {nome_ferramenta}
Categoria: {categoria}
Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}
Site: {link_oficial}
Idiomas Fonte: {', '.join(idiomas) if idiomas else 'PT-BR'}
---

{conteudo}
"""
    
    os.makedirs(pasta_categoria, exist_ok=True)
    
    with open(caminho, "w", encoding="utf-8") as f:
        f.write(conteudo_final)
    
    print(f"   ğŸ’¾ Salvo em: {caminho}")
    return caminho

# ============================================
# MAIN
# ============================================

def ler_fila():
    """LÃª fila de processamento e retorna lista de (nome, categoria)
    
    Formato esperado no arquivo:
    Nome da Ferramenta | Categoria
    
    Ignora linhas vazias e comentÃ¡rios (#)
    """
    arquivo_fila = os.path.join(os.path.dirname(BASE_PATH), "fila_processamento.txt")
    
    if not os.path.exists(arquivo_fila):
        print(f"\nâŒ Arquivo de fila nÃ£o encontrado: {arquivo_fila}")
        print("ğŸ’¡ Crie o arquivo com o formato: 'Nome da Ferramenta | Categoria'")
        return []
    
    ferramentas_fila = []
    
    with open(arquivo_fila, 'r', encoding='utf-8') as f:
        for linha in f:
            linha = linha.strip()
            
            # Ignora comentÃ¡rios e linhas vazias
            if not linha or linha.startswith('#'):
                continue
            
            # Parse: "Nome | Categoria"
            if '|' in linha:
                partes = linha.split('|')
                nome = partes[0].strip()
                categoria = partes[1].strip()
                ferramentas_fila.append((nome, categoria))
            else:
                # Formato antigo (sÃ³ nome, sem categoria) - tenta inferir
                nome = linha
                # Busca categoria no dicionÃ¡rio hardcoded (fallback)
                categoria = None
                for cat, tools in FERRAMENTAS_POR_CATEGORIA.items():
                    if nome in tools:
                        categoria = cat
                        break
                
                if categoria:
                    ferramentas_fila.append((nome, categoria))
                else:
                    print(f"   âš ï¸ Ferramenta '{nome}' sem categoria definida - pulando")
    
    return ferramentas_fila


def remover_da_fila(ferramentas_processadas):
    """Remove ferramentas processadas da fila (DELETA as linhas)
    
    Args:
        ferramentas_processadas: Lista de nomes de ferramentas que foram processadas
    """
    if not ferramentas_processadas:
        return
    
    arquivo_fila = os.path.join(os.path.dirname(BASE_PATH), "fila_processamento.txt")
    
    if not os.path.exists(arquivo_fila):
        return
    
    # LÃª arquivo
    with open(arquivo_fila, 'r', encoding='utf-8') as f:
        linhas = f.readlines()
    
    # Filtra linhas (remove as processadas)
    ferramentas_lower = [f.lower() for f in ferramentas_processadas]
    linhas_filtradas = []
    
    for linha in linhas:
        linha_stripped = linha.strip()
        
        # MantÃ©m comentÃ¡rios e linhas vazias
        if not linha_stripped or linha_stripped.startswith('#'):
            linhas_filtradas.append(linha)
            continue
        
        # Extrai nome da ferramenta (antes do |)
        if '|' in linha_stripped:
            nome_ferramenta = linha_stripped.split('|')[0].strip()
        else:
            nome_ferramenta = linha_stripped
        
        # Remove se foi processada
        if nome_ferramenta.lower() not in ferramentas_lower:
            linhas_filtradas.append(linha)
        # SenÃ£o, deleta a linha (nÃ£o adiciona em linhas_filtradas)
    
    # Reescreve arquivo
    with open(arquivo_fila, 'w', encoding='utf-8') as f:
        f.writelines(linhas_filtradas)
    
    print(f"\nğŸ§¹ Fila atualizada:")
    print(f"   âœ… {len(ferramentas_processadas)} ferramenta(s) REMOVIDA(S) da fila")


def main():
    import sys
    
    print("\n" + "="*70)
    print("  ğŸš€ GEODE SUPER CRAWLER V2.5 - SISTEMA DE FILA")
    print("="*70)
    print(f"  ğŸ“Š Limites API Gemini: {GEMINI_RPD} req/dia | {GEMINI_RPM} req/min | {GEMINI_TPM:,} tok/min")
    print(f"  â±ï¸ Delay entre requests: {GEMINI_DELAY_MIN}s")
    print(f"  âœ… Whisper IA: {'ATIVO' if WHISPER_DISPONIVEL else 'INATIVO'}")
    print("="*70 + "\n")
    
    # Configura Gemini
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel(MODELO_GEMINI)
    
    # LÃª fila de processamento
    fila = ler_fila()
    
    if not fila:
        print("âŒ Fila de processamento vazia ou arquivo nÃ£o encontrado!")
        print(f"ğŸ“ Edite: {os.path.join(os.path.dirname(BASE_PATH), 'fila_processamento.txt')}")
        return
    
    print(f"ğŸ“‹ Fila carregada: {len(fila)} ferramenta(s) pendente(s)\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MENU SIMPLIFICADO (TODAS AS OPÃ‡Ã•ES USAM A FILA)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    print("ğŸ“‹ ESCOLHA UMA OPÃ‡ÃƒO:\n")
    print("1ï¸âƒ£  Processar 5 FERRAMENTAS da fila (batch rÃ¡pido - ~15 min)")
    print("2ï¸âƒ£  Processar 1 FERRAMENTA da fila (primeira)")
    print("3ï¸âƒ£  Processar ferramenta ESPECÃFICA da fila (buscar por nome)")
    print("4ï¸âƒ£  Ver FILA completa (ferramentas pendentes)")
    print("5ï¸âƒ£  Sair\n")
    
    escolha = input("ğŸ‘‰ Sua opÃ§Ã£o (1-5): ").strip()
    
    if escolha == "5":
        print("\nğŸ‘‹ AtÃ© logo!\n")
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OPÃ‡ÃƒO 1: Processar 5 ferramentas DA FILA em batch
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if escolha == "1":
        print("\n" + "="*70)
        print("ğŸš€ MODO BATCH: Processando 5 ferramentas da fila")
        print("="*70)
        
        # Pega as 5 primeiras da fila (ou menos se nÃ£o houver 5)
        ferramentas_processar = fila[:5]
        
        print(f"\nğŸ“Š Fila total: {len(fila)} ferramenta(s)")
        print(f"ğŸ¯ Processando as {len(ferramentas_processar)} primeiras:\n")
        
        for i, (ferramenta, categoria) in enumerate(ferramentas_processar, 1):
            print(f"   {i}. {ferramenta} ({categoria})")
        
        print(f"\nâ±ï¸ Tempo estimado: ~{len(ferramentas_processar) * 3} minutos")
        print(f"ğŸ“Š Requests Gemini: {len(ferramentas_processar)}/{GEMINI_RPD}")
        
        confirma = input("\nâœ… Confirma processamento? (s/n): ").strip().lower()
        if confirma != 's':
            print("\nâŒ Cancelado")
            return
        
        # Processa
        sucesso = 0
        falhas = 0
        processadas = []
        
        for i, (ferramenta, categoria) in enumerate(ferramentas_processar, 1):
            print(f"\n{'='*70}")
            print(f"ğŸ“¦ Batch: {i}/{len(ferramentas_processar)}")
            print(f"{'='*70}")
            
            try:
                resultado = processar_ferramenta(ferramenta, categoria, model)
                if resultado:
                    sucesso += 1
                    processadas.append(ferramenta)
                else:
                    falhas += 1
            except Exception as e:
                print(f"\nâŒ ERRO: {e}")
                falhas += 1
        
        # Remove da fila
        remover_da_fila(processadas)
        
        # RelatÃ³rio
        print("\n" + "="*70)
        print("ğŸ“Š RELATÃ“RIO FINAL DO BATCH")
        print("="*70)
        print(f"âœ… Sucesso: {sucesso}")
        print(f"âŒ Falhas: {falhas}")
        print(f"ğŸ“ˆ Taxa: {(sucesso/len(ferramentas_processar)*100):.1f}%")
        print(f"ğŸ”¥ Requests: {gemini_requests_hoje}/{GEMINI_RPD}")
        print(f"ğŸ“‹ Restam na fila: {len(fila) - len(processadas)} ferramenta(s)")
        print("="*70 + "\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OPÃ‡ÃƒO 2: Processar 1 ferramenta DA FILA (primeira)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif escolha == "2":
        if not fila:
            print("\nğŸ‰ Fila vazia - todas processadas!")
            return
        
        ferramenta, categoria = fila[0]
        print(f"\nğŸ¯ Processando primeira da fila: {ferramenta} ({categoria})")
        print(f"ğŸ“‹ Ainda restam: {len(fila) - 1} ferramenta(s) apÃ³s esta")
        
        confirma = input("\nâœ… Confirma? (s/n): ").strip().lower()
        if confirma != 's':
            print("\nâŒ Cancelado")
            return
        
        resultado = processar_ferramenta(ferramenta, categoria, model)
        
        if resultado:
            remover_da_fila([ferramenta])
            print(f"\nâœ… {ferramenta} processada e removida da fila!")
        else:
            print(f"\nâŒ Falha ao processar {ferramenta}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OPÃ‡ÃƒO 3: Processar ferramenta ESPECÃFICA DA FILA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif escolha == "3":
        print("\nâœï¸ Digite o nome da ferramenta (deve estar na fila)")
        print(f"ğŸ’¡ Ferramentas disponÃ­veis na fila: {len(fila)}\n")
        
        # Mostra preview das primeiras 10
        print("ğŸ“‹ Primeiras 10 da fila:")
        for i, (nome, cat) in enumerate(fila[:10], 1):
            print(f"   {i}. {nome} ({cat})")
        
        if len(fila) > 10:
            print(f"   ... e mais {len(fila) - 10} ferramenta(s)")
        
        nome_input = input("\nğŸ‘‰ Nome da ferramenta: ").strip()
        
        if not nome_input:
            print("\nâŒ Nome vazio")
            return
        
        # Busca na fila (case-insensitive)
        ferramenta_encontrada = None
        categoria_encontrada = None
        
        for nome, cat in fila:
            if nome.lower() == nome_input.lower():
                ferramenta_encontrada = nome
                categoria_encontrada = cat
                break
        
        if not ferramenta_encontrada:
            print(f"\nâŒ '{nome_input}' nÃ£o encontrada na fila")
            print("ğŸ’¡ Use opÃ§Ã£o 4 para ver a fila completa")
            return
        
        print(f"\nâœ… Encontrado na fila: {ferramenta_encontrada} ({categoria_encontrada})")
        
        confirma = input("\nâœ… Processar agora? (s/n): ").strip().lower()
        if confirma != 's':
            print("\nâŒ Cancelado")
            return
        
        resultado = processar_ferramenta(ferramenta_encontrada, categoria_encontrada, model)
        
        if resultado:
            remover_da_fila([ferramenta_encontrada])
            print(f"\nâœ… {ferramenta_encontrada} processada e removida da fila!")
        else:
            print(f"\nâŒ Falha ao processar {ferramenta_encontrada}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OPÃ‡ÃƒO 4: Ver FILA completa
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif escolha == "4":
        print("\n" + "="*70)
        print("ğŸ“‹ FILA DE PROCESSAMENTO COMPLETA")
        print("="*70 + "\n")
        
        if not fila:
            print("ğŸ‰ Fila vazia - todas as ferramentas foram processadas!\n")
            return
        
        # Agrupa por categoria
        por_categoria = {}
        for nome, cat in fila:
            if cat not in por_categoria:
                por_categoria[cat] = []
            por_categoria[cat].append(nome)
        
        total = 0
        for cat in sorted(por_categoria.keys()):
            ferramentas = por_categoria[cat]
            print(f"\nğŸ“‚ {cat.upper()} ({len(ferramentas)} ferramenta(s))")
            print("-" * 50)
            
            for ferramenta in ferramentas:
                total += 1
                print(f"   {total:2d}. {ferramenta}")
        
        print("\n" + "="*70)
        print(f"ğŸ“Š Total na fila: {total} ferramenta(s)")
        print(f"â±ï¸ Tempo estimado (5 por batch): ~{(total // 5 + 1) * 15} minutos")
        print("="*70 + "\n")
    
    else:
        print("\nâŒ OpÃ§Ã£o invÃ¡lida\n")

if __name__ == "__main__":
    main()
